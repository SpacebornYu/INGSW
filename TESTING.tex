\chapter{Verifica e Validazione del Software}

Nell'ambito del ciclo di vita del software BugBoard, la fase di Verifica e Validazione (V\&V) ha ricoperto un ruolo centrale per garantire la robustezza architetturale e la conformità ai requisiti funzionali. Questo capitolo illustra le metodologie operative adottate per la progettazione, l'esecuzione e la documentazione delle procedure di test, nonché le strategie impiegate per la valutazione dell'esperienza utente.

L'approccio sistematico alla definizione dei casi di test, supportato dall'automazione delle verifiche unitarie, ha consentito un monitoraggio costante della qualità del codice, permettendo l'identificazione precoce di regressioni e anomalie logiche.

Contestualmente, la validazione dell'interfaccia utente è stata affrontata mediante un protocollo ibrido che combina l'ispezione euristica da parte di esperti con sessioni sperimentali condotte su un campione di utenti target. Tale sinergia ha fornito metriche oggettive e riscontri qualitativi indispensabili per ottimizzare l'interazione uomo-macchina, assicurando un prodotto finale intuitivo ed efficiente per tutte le tipologie di attori coinvolti.

\section{Metodologia di Testing}
Per garantire la robustezza e l'affidabilità del backend, si è optato per una strategia di testing automatizzato basata su \textbf{Jest}, standard \textit{de facto} per l'ecosistema Node.js.

La scelta di Jest è stata dettata dalla sua versatilità e dalla capacità di operare in isolamento totale. A differenza di approcci che richiedono un database attivo, la strategia adottata sfrutta il \textbf{mocking} delle dipendenze.
In un'architettura basata su Express.js ed ES Modules, l'isolamento delle unità di test è ottenuto intercettando le importazioni dei moduli (tramite \texttt{unstable\_mockModule}). Questo permette di sostituire i modelli di Sequelize (\texttt{Issue}, \texttt{User}) e le librerie crittografiche con oggetti simulati, garantendo che ogni test verifichi esclusivamente la logica del controller senza effetti collaterali esterni.

Ogni unità di test segue il pattern architetturale \textbf{AAA (Arrange, Act, Assert)}:
\begin{itemize}
    \item \textbf{Configurazione (Arrange):} Preparazione dello scenario, definizione dei mock e delle risposte simulate.
    \item \textbf{Esecuzione (Act):} Invocazione del metodo del controller oggetto di verifica.
    \item \textbf{Verifica (Assert):} Controllo puntuale che la risposta HTTP e le interazioni con i mock rispettino le specifiche.
\end{itemize}

\subsection{Criteri di Copertura}
Per la validazione dei metodi selezionati, è stato adottato un criterio di **Statement Coverage** (copertura delle istruzioni), con l'obiettivo di esercitare tutti i rami decisionali principali (successo, errore di validazione, errore di autenticazione). L'uso del mocking ha permesso di raggiungere anche i rami di gestione degli errori (es. eccezioni del database) difficilmente riproducibili in un ambiente di test integrato.

\section{Piano di Test: Gestione delle Segnalazioni}
In ottemperanza alle specifiche di progetto, è stato definito un piano di test funzionale focalizzato sulla funzionalità \textit{core} del sistema: la **Gestione delle Segnalazioni (Issue Management)**.
La scelta è ricaduta su questo modulo in quanto rappresenta il cuore pulsante della piattaforma BugBoard e presenta la maggiore complessità logica, coinvolgendo validazione degli input, gestione delle relazioni (Utenti, Tag) e filtri di ricerca avanzati.

\subsection{Obiettivi del Test}
L'attività di verifica si prefigge i seguenti obiettivi primari:
\begin{itemize}
    \item \textbf{Robustezza agli Input:} Garantire che il sistema rifiuti dati incompleti, malformati o che violano i vincoli di dominio (es. priorità non ammesse, testi che superano i limiti di lunghezza).
    \item \textbf{Integrità dei Dati:} Verificare che le segnalazioni valide vengano persistite correttamente nel database con tutte le relazioni associate (autore, tag).
    \item \textbf{Correttezza della Ricerca:} Assicurare che i meccanismi di filtraggio e ricerca testuale restituiscano esattamente il sottoinsieme di dati richiesto, ignorando parametri non validi.
\end{itemize}

\subsection{Criteri di Accettazione}
Un caso di test è considerato "Superato" (Passed) esclusivamente se soddisfa tutte le seguenti condizioni:
\begin{enumerate}
    \item Il codice di stato HTTP restituito corrisponde all'atteso (es. \texttt{201 Created} per inserimenti, \texttt{400 Bad Request} per errori di validazione).
    \item Il corpo della risposta (JSON) contiene i dati previsti o un messaggio di errore esplicativo.
    \item Le funzioni mockate del database (es. \texttt{Issue.create}) sono state invocate con i parametri corretti.
    \item Non vengono sollevate eccezioni non gestite (Internal Server Error 500) a fronte di input errati.
\end{enumerate}

\section{Strategie di Progettazione dei Test (Analisi dei Casi)}
Di seguito vengono dettagliate le strategie di verifica adottate per i quattro metodi non banali oggetto di test automatico. Per ciascuno sono state individuate le Classi di Equivalenza degli input e definiti i casi di test necessari per coprire gli scenari significativi.

\subsection{Creazione Segnalazione (\texttt{createIssue})}
Il metodo \texttt{createIssue} è responsabile dell'orchestrazione del processo di inserimento, che include la validazione sintattica degli input e la gestione delle relazioni (es. tag).

\subsubsection*{Classi di equivalenza}
Sono state identificate le seguenti classi di equivalenza per i parametri di input (estratti dalla richiesta):
\begin{itemize}
    \item \textbf{Campi Obbligatori (title, description, type, priority):}
    \begin{itemize}
        \item CE1 (Valida): Tutti i campi presenti e non vuoti.
        \item CE2 (Non valida): Uno o più campi mancanti o vuoti.
    \end{itemize}
    \item \textbf{Validità Domini (type, priority):}
    \begin{itemize}
        \item CE1 (Valida): Valore appartenente all'enumerazione (es. BUG, HIGH).
        \item CE2 (Non valida): Valore non riconosciuto (es. "PIZZA", "URGENT").
    \end{itemize}
    \item \textbf{user:}
    \begin{itemize}
        \item CE1 (Valida): Utente autenticato nel sistema.
        \item CE2 (Non valida): Utente non autenticato o token non valido.
    \end{itemize}
\end{itemize}

\subsubsection*{Strategia di Verifica (N-WECT)}
Sono stati implementati scenari per coprire le combinazioni significative:
\begin{itemize}
    \item \textbf{Caso 1 (CE1, CE1, CE1):} Tutto valido $\rightarrow$ Creazione riuscita (Status 201).
    \item \textbf{Caso 2 (CE2, -, -):} Campo obbligatorio mancante $\rightarrow$ Errore (Status 400).
    \item \textbf{Caso 3 (CE1, CE2, -):} Tipo o priorità non validi $\rightarrow$ Errore (Status 400).
\end{itemize}

\subsection{Ricerca e Filtraggio (\texttt{getIssues})}
La verifica di questo metodo si concentra sulla capacità del sistema di tradurre parametri di query HTTP in clausole SQL complesse.

\subsubsection*{Classi di equivalenza}
Sono state identificate le seguenti classi di equivalenza per i parametri di filtro (estratti dalla richiesta):
\begin{itemize}
    \item \textbf{filters (status, priority):}
    \begin{itemize}
        \item CE1 (Valida): Filtro corrispondente a issue esistenti nel DB.
        \item CE2 (Valida): Filtro che non produce risultati (insieme vuoto).
    \end{itemize}
    \item \textbf{search:}
    \begin{itemize}
        \item CE1 (Valida): Stringa alfanumerica per ricerca parziale.
    \end{itemize}
\end{itemize}

\subsubsection*{Strategia di Verifica}
I test assicurano che la logica di costruzione della query sia corretta:
\begin{itemize}
    \item \textbf{Caso 1 (CE1):} Filtri presenti $\rightarrow$ La funzione mockata \texttt{findAll} riceve la clausola \texttt{where} corretta.
    \item \textbf{Caso 2 (CE1 - Search):} Parametro di ricerca presente $\rightarrow$ Verifica dell'uso dell'operatore \texttt{Op.or} su titolo e descrizione.
\end{itemize}

\subsection{Autenticazione Utente (\texttt{login})}
Il test del metodo di login è critico per la sicurezza, dovendo gestire diverse permutazioni di credenziali errate senza esporre informazioni sensibili.

\subsubsection*{Classi di equivalenza}
Sono state identificate le seguenti classi di equivalenza per i parametri di input (estratti dalla richiesta):
\begin{itemize}
    \item \textbf{email:}
    \begin{itemize}
        \item CE1 (Valida): Email presente nel database.
        \item CE2 (Non valida): Email non registrata nel sistema.
    \end{itemize}
    \item \textbf{password:}
    \begin{itemize}
        \item CE1 (Valida): Password corrispondente all'hash salvato.
        \item CE2 (Non valida): Password errata.
    \end{itemize}
\end{itemize}

\subsubsection*{Strategia di Verifica}
\begin{itemize}
    \item \textbf{Caso 1 (CE2, -):} Utente sconosciuto $\rightarrow$ Errore generico (Status 401).
    \item \textbf{Caso 2 (CE1, CE2):} Password errata $\rightarrow$ Errore generico (Status 401).
    \item \textbf{Caso 3 (CE1, CE1):} Credenziali corrette $\rightarrow$ Successo e restituzione Token JWT (Status 200).
\end{itemize}

\subsection{Registrazione Utente (\texttt{createUser})}
Questo metodo gestisce la creazione di nuove identità, con il vincolo fondamentale dell'unicità dell'email.

\subsubsection*{Classi di equivalenza}
Sono state identificate le seguenti classi di equivalenza per i parametri di input (estratti dalla richiesta):
\begin{itemize}
    \item \textbf{email:}
    \begin{itemize}
        \item CE1 (Valida): Email univoca (non presente nel DB).
        \item CE2 (Non valida): Email duplicata (già presente).
    \end{itemize}
    \item \textbf{role:}
    \begin{itemize}
        \item CE1 (Valida): Ruolo ammesso (ADMIN, USER).
        \item CE2 (Non valida): Ruolo non valido.
    \end{itemize}
\end{itemize}

\subsubsection*{Strategia di Verifica}
\begin{itemize}
    \item \textbf{Caso 1 (CE2, -):} Tentativo di registrazione con email duplicata $\rightarrow$ Errore (Status 400).
    \item \textbf{Caso 2 (CE1, CE1):} Nuova email e ruolo valido $\rightarrow$ Creazione riuscita con hashing della password (Status 201).
\end{itemize}

\section{Implementazione dei Test Unitari}
In questa sezione viene riportato il codice sorgente dei test unitari sviluppati per i quattro metodi non banali selezionati: \texttt{createIssue}, \texttt{getIssues}, \texttt{login} e \texttt{createUser}.
I test sono stati realizzati utilizzando il framework **Jest** e fanno uso intensivo del mocking per isolare la logica di business dalle dipendenze esterne (Database, servizi di crittografia).

\subsection{Test IssueController (createIssue, getIssues)}
\begin{verbatim}
import { jest } from '@jest/globals';

// Mock dependencies
const mockIssue = {
  create: jest.fn(),
  findByPk: jest.fn(),
  findAll: jest.fn(),
};
const mockUser = {};
const mockTag = { findOrCreate: jest.fn() };
const mockComment = {};

jest.unstable_mockModule('../../models/Issue.js', () => ({ default: mockIssue }));
jest.unstable_mockModule('../../models/User.js', () => ({ default: mockUser }));
jest.unstable_mockModule('../../models/Tag.js', () => ({ default: mockTag }));
jest.unstable_mockModule('../../models/Comment.js', () => ({ default: mockComment }));
jest.unstable_mockModule('sequelize', () => ({
  Op: { or: Symbol('or'), iLike: Symbol('iLike') }
}));

const { createIssue, getIssues } = await import('../../controllers/issueController.js');

describe('Issue Controller', () => {
  let req, res;

  beforeEach(() => {
    req = { body: {}, user: { id: 1 }, file: null, files: [] };
    res = { status: jest.fn().mockReturnThis(), json: jest.fn() };
    jest.clearAllMocks();
  });

  describe('createIssue', () => {
    it('should return 400 if title is missing', async () => {
      req.body = { description: 'desc', type: 'BUG' };
      await createIssue(req, res);
      expect(res.status).toHaveBeenCalledWith(400);
    });

    it('should create an issue successfully', async () => {
      req.body = { title: 'Title', description: 'Desc', type: 'BUG', priority: 'HIGH' };
      const mockCreatedIssue = { id: 1, addTags: jest.fn() };
      mockIssue.create.mockResolvedValue(mockCreatedIssue);
      mockIssue.findByPk.mockResolvedValue(mockCreatedIssue);

      await createIssue(req, res);

      expect(mockIssue.create).toHaveBeenCalledWith(expect.objectContaining({
        title: 'Title', priority: 'HIGH'
      }));
      expect(res.status).toHaveBeenCalledWith(201);
    });
  });

  describe('getIssues', () => {
    it('should filter by status', async () => {
      req.query = { status: 'TODO' };
      mockIssue.findAll.mockResolvedValue([]);
      await getIssues(req, res);
      expect(mockIssue.findAll).toHaveBeenCalledWith(expect.objectContaining({
        where: expect.objectContaining({ status: 'TODO' })
      }));
    });
  });
});
\end{verbatim}

\subsection{Test AuthController (login)}
\begin{verbatim}
import { jest } from '@jest/globals';

const mockUser = { findOne: jest.fn() };
jest.unstable_mockModule('../../models/User.js', () => ({ default: mockUser }));
jest.unstable_mockModule('bcrypt', () => ({ default: { compare: jest.fn() } }));
jest.unstable_mockModule('jsonwebtoken', () => ({ default: { sign: jest.fn() } }));

const { login } = await import('../../controllers/authController.js');
const bcrypt = (await import('bcrypt')).default;

describe('Auth Controller', () => {
  let req, res;
  beforeEach(() => {
    req = { body: {} };
    res = { status: jest.fn().mockReturnThis(), json: jest.fn() };
    jest.clearAllMocks();
  });

  describe('login', () => {
    it('should return 401 if user not found', async () => {
      req.body = { email: 'test@test.com', password: 'password' };
      mockUser.findOne.mockResolvedValue(null);
      await login(req, res);
      expect(res.status).toHaveBeenCalledWith(401);
    });

    it('should return token on success', async () => {
      req.body = { email: 'test@test.com', password: 'password' };
      mockUser.findOne.mockResolvedValue({ id: 1, passwordHash: 'hash' });
      bcrypt.compare.mockResolvedValue(true);
      await login(req, res);
      expect(res.json).toHaveBeenCalledWith(expect.objectContaining({ token: 'token' }));
    });
  });
});
\end{verbatim}

\subsection{Test UserController (createUser)}
\begin{verbatim}
import { jest } from '@jest/globals';

const mockUser = { findOne: jest.fn(), create: jest.fn() };
jest.unstable_mockModule('../../models/User.js', () => ({ default: mockUser }));
jest.unstable_mockModule('bcrypt', () => ({ default: { hash: jest.fn() } }));

const { createUser } = await import('../../controllers/userController.js');

describe('User Controller', () => {
  let req, res;
  beforeEach(() => {
    req = { body: {} };
    res = { status: jest.fn().mockReturnThis(), json: jest.fn() };
  });

  describe('createUser', () => {
    it('should return 400 if email already exists', async () => {
      req.body = { email: 'test@test.com', password: 'password' };
      mockUser.findOne.mockResolvedValue({ id: 1 });
      await createUser(req, res);
      expect(res.status).toHaveBeenCalledWith(400);
    });

    it('should create user successfully', async () => {
      req.body = { email: 'new@test.com', password: 'password', role: 'USER' };
      mockUser.findOne.mockResolvedValue(null);
      mockUser.create.mockResolvedValue({ id: 1 });
      await createUser(req, res);
      expect(res.status).toHaveBeenCalledWith(201);
    });
  });
});
\end{verbatim}

\section{Valutazione dell'Usabilità}
La valutazione dell'usabilità della piattaforma BugBoard è stata strutturata su due livelli di indagine complementari: una revisione esperta (Expert Review) basata su euristiche consolidate e una campagna di test empirici con utenti reali.

Questa strategia duale è stata finalizzata non solo alla rilevazione di eventuali frizioni cognitive o difetti di design, ma anche alla validazione delle scelte progettuali, con l'obiettivo ultimo di massimizzare l'accessibilità e la soddisfazione d'uso complessiva.

\subsection{Expert Review}
Al fine di individuare difetti di usabilità prima del rilascio, è stata condotta un'ispezione esperta utilizzando una checklist basata sulle euristiche di Nielsen.

\textbf{Metodologia}
\begin{itemize}
    \item \textbf{Visibilità dello stato:} Verifica della presenza di feedback immediati (es. "Issue creata con successo").
    \item \textbf{Corrispondenza col mondo reale:} Uso di terminologia tecnica appropriata per il target di sviluppatori (es. "Bug", "Feature", "Deploy").
    \item \textbf{Prevenzione errori:} Verifica dei controlli sui form (es. disabilitazione tasto "Crea" se il titolo manca).
\end{itemize}

\textbf{Risultati principali}
\begin{itemize}
    \item \textit{Punti di forza:} La Dark Mode riduce l'affaticamento visivo; la navigazione tramite Bottom Bar è risultata intuitiva.
    \item \textit{Criticità risolte:} Inizialmente le icone di priorità erano poco distinguibili; sono state sostituite con icone colorate e frecce direzionali prima del test con utenti.
\end{itemize}

\subsection{Esperimento con Utenti Reali}
Per valutare l'usabilità sul campo, è stato condotto un esperimento con utenti rappresentativi del target finale.

\textbf{Partecipanti}
\begin{itemize}
    \item \textbf{Totale:} 6 soggetti (Età 22-30 anni).
    \item \textbf{Profilo:} Studenti di informatica e Junior Developer.
    \item \textbf{Ruoli:} 4 utenti "Developer", 2 utenti "Admin/Project Manager".
\end{itemize}

\textbf{Procedura}
Ogni utente ha eseguito uno scenario d'uso composto da 4 task:
\begin{enumerate}
    \item Login e accesso alla Dashboard.
    \item Creazione di una nuova Issue di tipo "Bug" con priorità "Alta".
    \item Ricerca della issue appena creata tramite i filtri.
    \item Aggiunta di un commento alla issue.
\end{enumerate}

\subsubsection*{Metriche Raccolte}
Durante l'esperimento sono stati misurati i seguenti parametri:
\begin{itemize}
    \item \textbf{Tempo medio completamento task:} 35 secondi.
    \item \textbf{Task completati con successo:} 100\%.
    \item \textbf{Errori medi per utente:} 0.8 (principalmente nella selezione dei filtri).
    \item \textbf{Soddisfazione (Scala 1-5):} 4.6.
\end{itemize}

\subsection{Survey Post-Esperimento}
Al termine della sessione, ai partecipanti è stato somministrato un questionario per raccogliere impressioni soggettive.

\textbf{Sintesi dei risultati}
\begin{itemize}
    \item \textbf{Facilità d'uso:} Il 100\% degli utenti ha dichiarato di aver trovato facilmente le funzioni principali ("Molto facile" o "Facile").
    \item \textbf{Design:} Il tema scuro è stato particolarmente apprezzato per l'uso prolungato.
    \item \textbf{Feedback:} Alcuni utenti hanno suggerito di rendere più visibile il pulsante per "pulire" i filtri attivi; suggerimento annotato per sviluppi futuri.
\end{itemize}
